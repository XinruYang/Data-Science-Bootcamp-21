{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch & Pipelines\n",
    "GridSearch is an optimization tool that we use when tuning hyperparameters. We define the grid of parameters that we want to search through, and we select the best combination of parameters for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - One way\n",
    "Itera un algoritmo sobre un conjunto de hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.1, 0.5, 1, 5, 10],\n",
       "                         'gamma': ('scale', 'auto'),\n",
       "                         'kernel': ('linear', 'rbf', 'sigmoid')},\n",
       "             verbose=2)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "svc = svm.SVC()\n",
    "\n",
    "parameters = {\n",
    "    'kernel': ('linear', 'rbf', 'sigmoid'),\n",
    "    'C': [0.001, 0.1, 0.5, 1, 5, 10],\n",
    "    'gamma': ('scale', 'auto')\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(estimator = svc,\n",
    "                  param_grid = parameters,\n",
    "                  n_jobs=-1,\n",
    "                  cv=10,\n",
    "                  verbose=2)\n",
    "\n",
    "clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVC(C=0.5, kernel='linear')\n0.9866666666666667\n{'C': 0.5, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Almost-Pro way\n",
    "\n",
    "La forma pro es la que hace esto mismo y va recogiendo los errores de entrenamiento, de validación y tiene la capacidad de parar el proceso cuando se requiera además de guardar el modelo en local una vez terminado si es mejor que el que había anteriormente y de cargar el modelo anterior y seguir reentrenando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 53 candidates, totalling 530 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 530 out of 530 | elapsed:    8.3s finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('classifier',\n",
       "                                        RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'classifier': [LogisticRegression()],\n",
       "                          'classifier__C': [0.01, 0.1, 0.5, 1],\n",
       "                          'classifier__penalty': ['l1', 'l2']},\n",
       "                         {'classifier': [RandomForestClassifier()],\n",
       "                          'classifier__max_features': [1, 2, 3],\n",
       "                          'classifier__n_estimators': [10, 100, 1000]},\n",
       "                         {'classifier': [SVC(C=0.1, kernel='linear')],\n",
       "                          'classifier__C': [0.001, 0.1, 0.5, 1, 5, 10],\n",
       "                          'classifier__gamma': ('scale', 'auto'),\n",
       "                          'classifier__kernel': ('linear', 'rbf', 'sigmoid')}],\n",
       "             verbose=1)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "logistic_params = {\n",
    "    'classifier': [LogisticRegression()],\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    \"classifier__C\": [0.01, 0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "random_forest_params = {\n",
    "    'classifier': [RandomForestClassifier()],\n",
    "    'classifier__n_estimators': [10, 100, 1000],\n",
    "    'classifier__max_features': [1,2,3]\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'classifier': [SVC()],\n",
    "    'classifier__kernel': ('linear', 'rbf', 'sigmoid'),\n",
    "    'classifier__C': [0.001, 0.1, 0.5, 1, 5, 10],\n",
    "    'classifier__gamma': ('scale', 'auto')\n",
    "    \n",
    "}\n",
    "\n",
    "search_space = [\n",
    "    logistic_params,\n",
    "    random_forest_params,\n",
    "    svm_params\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = search_space,\n",
    "                  cv = 10,\n",
    "                  verbose=1,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pipeline(steps=[('classifier', SVC(C=0.1, kernel='linear'))])\n{'classifier': SVC(C=0.1, kernel='linear'), 'classifier__C': 0.1, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}\n0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCIONAMIENTO DE CROSS VALIDATION POR DENTRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "y = np.array([\"a\", \"b\", \"b\", \"a\", \"a\", \"b\"])\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=2 # Las épocas, el nº de veces que hace algo \n",
    ", random_state=1) # Lo que va a hacer es coger datos de dos en dos, y que cada epoca tiene que acabarse en 3 iteraciones # Nunca puede ocurrir que escoja muestras con clases que se repitan, a diferencia de ReapeatedKFold. Si se puede es mejor el ReapitedStratifiedKFold. \n",
    "\n",
    "########## Epoch1 ############\n",
    "x_train = [2, 3, 4, 5]\n",
    "y_train = y = [\"b\", \"b\", \"a\", \"a\"]\n",
    "x_val1 = [1, 6]\n",
    "y_val1 = [\"a\", \"b\"]\n",
    "##############################################################\n",
    "x_train = [1, 3, 4, 6]\n",
    "y_train = y = [\"a\", \"b\", \"a\", \"b\"]\n",
    "x_val2 = [5, 2]\n",
    "y_val2 = [\"a\", \"b\"]\n",
    "##############################################################\n",
    "x_train = [1, 2, 5, 6]\n",
    "y_train = y = [\"a\", \"b\", \"a\", \"b\"]\n",
    "x_val3 = [3, 4]\n",
    "y_val3 = [\"b\", \"a\"]\n",
    "\n",
    "# la validación se hace durante el entrenamiento"
   ]
  },
  {
   "source": [
    "### FUNCIONAMIENTO DEL CROSS VALIDATION POR DENTRO"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAIN: [1 2 3 4] VAL [0 5]\n",
      "score_val 0.0\n",
      "TRAIN: [0 2 3 5] VAL [1 4]\n",
      "score_val 0.5\n",
      "TRAIN: [0 1 4 5] VAL [2 3]\n",
      "score_val 1.0\n",
      "TRAIN: [2 3 4 5] VAL [0 1]\n",
      "score_val 0.5\n",
      "TRAIN: [0 1 2 3] VAL [4 5]\n",
      "score_val 0.5\n",
      "TRAIN: [0 1 4 5] VAL [2 3]\n",
      "score_val 1.0\n",
      "X[train_index] [[2]\n",
      " [3]\n",
      " [4]\n",
      " [5]]\n"
     ]
    }
   ],
   "source": [
    "# Este es el funcionamiento interno de la validación cruzada, no lo usamos\n",
    "\n",
    "# La validación es una buena práctica\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([1, 2, 3, 4, 5, 6]).reshape(-1, 1)\n",
    "\n",
    "y = np.array([\"a\", \"b\", \"b\", \"a\", \"a\", \"b\"])\n",
    "\n",
    "rand_forest = RandomForestClassifier()\n",
    "rskf = RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=1)\n",
    "for train_index, val_index in rskf.split(X,y):\n",
    "    print(\"TRAIN:\", train_index, \"VAL\", val_index)\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    rand_forest.fit(X_train, y_train)\n",
    "    score_val = rand_forest.score(X_val, y_val)\n",
    "    print(\"score_val\", score_val)\n",
    "\n",
    "\n",
    "# Iteracion 1 \n",
    "train_index = [1, 2, 3, 4]\n",
    "val_index = [0, 5]\n",
    "\n",
    "print(\"X[train_index]:\", X[train_index])"
   ]
  },
  {
   "source": [
    "# 3 Another way"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'gs_reg_log': GridSearchCV(cv=10,\n",
       "              estimator=Pipeline(steps=[('imputer', SimpleImputer()),\n",
       "                                        ('scaler', StandardScaler()),\n",
       "                                        ('reglog', LogisticRegression())]),\n",
       "              n_jobs=-1,\n",
       "              param_grid={'imputer__strategy': ['mean', 'median',\n",
       "                                                'most_frequent'],\n",
       "                          'reglog__C': [0.01, 0.1, 0.5, 1],\n",
       "                          'reglog__penalty': ['l1', 'l2']},\n",
       "              scoring='accuracy', verbose=1),\n",
       " 'gs_rand_forest': GridSearchCV(cv=10, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "              param_grid={'max_features': [1, 2, 3],\n",
       "                          'n_estimators': [10, 100, 1000]},\n",
       "              scoring='accuracy', verbose=1),\n",
       " 'gs_svm': GridSearchCV(cv=10,\n",
       "              estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                        ('selectkbest', SelectKBest()),\n",
       "                                        ('svm', SVC())]),\n",
       "              n_jobs=-1,\n",
       "              param_grid={'selectkbest__k': [1, 2, 3],\n",
       "                          'svm__C': [0.001, 0.1, 0.5, 1, 5, 10],\n",
       "                          'svm__gamma': ('scale', 'auto'),\n",
       "                          'svm__kernel': ('linear', 'rbf', 'sigmoid')},\n",
       "              scoring='accuracy', verbose=1)}"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "reg_log = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer()), # Nos quita los valores Nan\n",
    "    (\"scaler\", StandardScaler()), # Nos estandariza los datos\n",
    "    (\"reglog\", LogisticRegression()) # Queremos que se entrene con la regresión logística\n",
    "])\n",
    "\n",
    "rand_forest = RandomForestClassifier()\n",
    "\n",
    "svm = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"selectkbest\", SelectKBest()), # Tengo 60 columnas y quiero que me selecciones 40\n",
    "    (\"svm\", SVC()) # Queremos que se entrene con SVC\n",
    "])\n",
    "\n",
    "reg_log_param = {\n",
    "    \"imputer__strategy\": ['mean', 'median', 'most_frequent'], # Va a probar la media con l1 y 0.1, l1 y 0.2 ,...., l2 y 0.1, ....\n",
    "    \"reglog__penalty\": ['l1', 'l2'], # penalty\n",
    "    \"reglog__C\": [0.01, 0.1, 0.5, 1] # C\n",
    "}\n",
    "\n",
    "rand_forest_param = {\n",
    "    'n_estimators': [10, 100, 1000],\n",
    "    'max_features': [1,2,3]\n",
    "}\n",
    "\n",
    "svm_param = {\n",
    "    'selectkbest__k': [1,2,3],\n",
    "    'svm__kernel': ('linear', 'rbf', 'sigmoid'),\n",
    "    'svm__C': [0.001, 0.1, 0.5, 1, 5, 10],\n",
    "    'svm__gamma': ('scale', 'auto')\n",
    "    \n",
    "}\n",
    "\n",
    "# cv = RepeatedKFold(n_splits=10, n_repeats=1, random_state=1) SERÍA LO QUE SE PASA A CV\n",
    "\n",
    "gs_reg_log = GridSearchCV(reg_log,\n",
    "                         reg_log_param,\n",
    "                         cv = 10, # cross validation: hacemos 10 conjuntos de validación que no se van a repetir\n",
    "                         scoring = 'accuracy',\n",
    "                         verbose=1,\n",
    "                         n_jobs=-1)\n",
    "\n",
    "gs_rand_forest = GridSearchCV(rand_forest,\n",
    "                         rand_forest_param,\n",
    "                         cv = 10,\n",
    "                         scoring = 'accuracy',\n",
    "                         verbose=1,\n",
    "                         n_jobs=-1)\n",
    "\n",
    "gs_svm = GridSearchCV(svm, svm_param,\n",
    "                         cv = 10,\n",
    "                         scoring = 'accuracy',\n",
    "                         verbose=1,\n",
    "                         n_jobs=-1)\n",
    "\n",
    "grids = {\n",
    "    \"gs_reg_log\": gs_reg_log,\n",
    "    \"gs_rand_forest\": gs_rand_forest,\n",
    "    \"gs_svm\": gs_svm\n",
    "}\n",
    "\n",
    "grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.0s\n",
      "#################\n",
      "NOMBRE: gs_reg_log\n",
      "#################\n",
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "#################\n",
      "NOMBRE: gs_rand_forest\n",
      "#################\n",
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  90 | elapsed:    3.3s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    4.6s finished\n",
      "#################\n",
      "NOMBRE: gs_svm\n",
      "#################\n",
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.0s\n",
      "Wall time: 6.61 s\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for nombre, grid in grids.items():\n",
    "    print(\"#################\")\n",
    "    print(\"NOMBRE:\", nombre)\n",
    "    print(\"#################\")\n",
    "    grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Grid  Best score\n",
       "2          gs_svm    0.958333\n",
       "0      gs_reg_log    0.941667\n",
       "1  gs_rand_forest    0.933333"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Grid</th>\n      <th>Best score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>gs_svm</td>\n      <td>0.958333</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>gs_reg_log</td>\n      <td>0.941667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gs_rand_forest</td>\n      <td>0.933333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "import pandas as pd\n",
    "best_grids = [(i, j.best_score_) for i, j in grids.items()]\n",
    "\n",
    "best_grids = pd.DataFrame(best_grids,\n",
    "                         columns = ['Grid', 'Best score']).sort_values(by = 'Best score', ascending=False)\n",
    "best_grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('selectkbest', SelectKBest()),\n",
       "                                       ('svm', SVC())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'selectkbest__k': [1, 2, 3],\n",
       "                         'svm__C': [0.001, 0.1, 0.5, 1, 5, 10],\n",
       "                         'svm__gamma': ('scale', 'auto'),\n",
       "                         'svm__kernel': ('linear', 'rbf', 'sigmoid')},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "best_model = grids['gs_svm']\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('selectkbest', SelectKBest(k=2)),\n                ('svm', SVC(C=0.5, kernel='sigmoid'))])\n"
     ]
    }
   ],
   "source": [
    "print(best_model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "best_model.best_estimator_.fit(X_train, y_train)\n",
    "best_model.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SVC(C=0.5, kernel='sigmoid')"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "best_model.best_estimator_['svm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'finished_model.model'\n",
    "\n",
    "with open(filename, 'wb') as archivo_salida:\n",
    "    pickle.dump(best_model.best_estimator_, archivo_salida)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('selectkbest', SelectKBest(k=2)),\n",
       "                ('svm', SVC(C=0.5, kernel='sigmoid'))])"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "with open(filename, 'rb') as archivo_entrada:\n",
    "    pipeline_importada = pickle.load(archivo_entrada)\n",
    "pipeline_importada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 2, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "pipeline_importada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "5c4d2f1fdcd3716c7a5eea90ad07be30193490dd4e63617705244f5fd89ea793"
   }
  },
  "interpreter": {
   "hash": "fc2c00f0e2c44cb4028bd693f18a1b5d93d1de4cd12db71fca36ff691a163044"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}